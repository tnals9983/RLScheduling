from __future__ import annotations
import csv
from gym import spaces
import numpy as np
import gym
from gym.utils import seeding
from or_gym.utils import assign_env_config
import pandas as pd
import copy
from copy import deepcopy
from numpy import random
import datetime

import gym
from gym import spaces, logger
import pandas as pd
import numpy as np
import openpyxl

from ray.rllib.utils.spaces.space_utils import flatten_space

class SingleStage(gym.Env):

        def __init__(self, *arg, **kwargs):
                df_time = pd.read_csv('/dataset/envdata.csv')
                df_date = pd.read_csv('/dataset/datedata.csv')
                df_cost = pd.read_csv('/dataset/costdata.csv')
                timedata = df_time.drop(df_time.columns[[0]], axis=1)
                self.release_date = df_date.loc[:, 'release']
                self.due_date = df_date.loc[:, 'due']
                costdata = df_cost.drop(df_cost.columns[[0]], axis=1)
                self.cost = costdata.values
                self.processing_time = timedata.values
                #############################################################################################
                #process-scale
                self.task_N = len(costdata.index)
                self.machine_N = len(costdata.columns)
                #############################################################################################
                self.step_count = 0
                self.step_limit = max((self.due_date)+2) 
                self.mask = True
                self.cost_sum = 0
                self.selected_task = []
                self.current_task = []
                self.selected = np.zeros(self.task_N)
                self.machines = []
                self.start_time = np.zeros(self.task_N)


                due_ptime = np.zeros((self.task_N, self.machine_N))
                for i in range(self.task_N):
                        for j in range(self.machine_N):
                                due_ptime[i, j] = self.due_date[i] - self.processing_time[i, j]
                self.max_due_ptime = int(np.max(due_ptime))

                for i in range(self.task_N):
                        self.machines.append(-1)

                for i in range(self.machine_N):
                        self.current_task.append(-1)

                def init_list_of_objects(size):
                        list_of_objects = list()
                        for i in range(0, size):
                                list_of_objects.append(list())  # different object reference each time
                        return list_of_objects

                self.machine_task = init_list_of_objects(self.machine_N)  # machine-task allocation data

                #action space
                actionspace = [self.task_N + 1] * self.machine_N
                self.action_space = gym.spaces.MultiDiscrete(actionspace)
                self.obs_space = spaces.Box(-1000,1000,shape=(self.task_N*2,))

                self.observation_space = spaces.Dict({
                                "action_mask": spaces.Box(0, 1, shape=((self.task_N +1) * self.machine_N,)),
                                # "avail_actions" : spaces.Box(0,1, shape=(2,self.task_N)),
                                "observations": self.obs_space
                        })

                self.reset()

        def _RESET(self):
                self.step_count = 0
                self.cost_sum = 0
                self.selected_task = []
                self.selected = np.zeros(self.task_N)
                self.machines = []
                self.current_task = []
                self.start_time = np.zeros(self.task_N)

                for i in range(self.task_N):
                        self.machines.append(-1)

                for i in range(self.machine_N):
                        self.current_task.append(-1)


                def init_list_of_objects(size):
                        list_of_objects = list()
                        for i in range(0, size):
                                list_of_objects.append(list())  # different object reference each time
                        return list_of_objects

                self.machine_task = init_list_of_objects(self.machine_N)  # machine-task allocation data

                i = self.step_limit + 1
                j = self.machine_N
                k = self.task_N + 1

                self.masked_action = np.ones((i, j, k))
                for t in range(1, k):
                        for m in range(j):
                                for ii in range(self.release_date[t - 1]):
                                        self.masked_action[ii, m, t] = 0
                                for iii in range(self.due_date[t - 1] - self.processing_time[t - 1, m] + 1, i):
                                        self.masked_action[iii, m, t] = 0


                self.observations = np.hstack([self.machines , self.start_time])
                self.state = {
                        "action_mask": np.ravel(self.masked_action[0]),
                        "observations": np.ravel(self.observations)
                }
                return self.state

        def _STEP(self,action):
                reward = 0

                self.actions = []
                action_list = []
                for i in range(self.machine_N):
                        self.actions.extend([action[i]])
                        action_list.extend([action[i]])
                while 0 in action_list:
                        action_list.remove(0)

                if self.step_count < self.step_limit-1:
                        if len(set(action_list)) != len(action_list): #prevent selecting same task
                                reward += - 110
                                done = True
                        else:
                                for i in range(int(self.machine_N)):
                                        if action[i] == 0 :
                                                self.cost_sum += 0
                                                # self.end_time[i] = self.step_count+1
                                                reward += 0
                                                done = False
                                        else :
                                                self.current_task[i] = action[i]-1


                                                if self.step_count < self.release_date[self.current_task[i]] or \
                                                        self.step_count > self.due_date[self.current_task[i]]-self.processing_time[self.current_task[i],i]:
                                                        reward += -300
                                                        done = True
                                                else:
                                                        self.cost_sum += self.cost[self.current_task[i], i]
                                                        self.selected_task.append(self.current_task[i])
                                                        self.selected[self.current_task[i]] = 1
                                                        self.machines[self.current_task[i]] = i
                                                        self.machine_task[i].append(self.current_task[i])
                                                        self.start_time[self.current_task[i]] = self.step_count
                                                        # self.end_time[i] = int(self.step_count+self.processing_time[self.current_task[i],i])
                                                        reward += -self.cost[self.current_task[i], i] * (10**(-2))
                                                        done  = False

                else:
                        if len(self.selected_task) != self.task_N:
                                if len(self.selected_task) > 0:
                                        reward += -100 * 1 / len(self.selected_task)
                                else:
                                        reward += -110
                        elif len(self.selected_task) == self.task_N:
                                reward += 0
                        done = True

                self._update_state()

                return self.state, reward, done, {}

        def _update_state(self):
                for idx, val in enumerate(self.actions):
                        if val > 0 :
                                self.masked_action[self.step_count:self.step_count+self.processing_time[val-1,idx],idx,1:] = 0 #occupied machine masking
                                self.masked_action[self.step_count+1:,:,val] = 0 #selected task masking

                self.observations = np.hstack([self.machines , self.start_time])
                self.step_count += 1
                self.state = {
                        "action_mask" : np.ravel(self.masked_action[self.step_count]),
                        # "avail_actions" : np.ones((2,self.task_N+1)),
                        "observations" : np.ravel(self.observations)
                }
                # self.step_count += 1

        def step(self, action):
                return self._STEP(action)

        def reset(self):
                return self._RESET()

SingleStage()
